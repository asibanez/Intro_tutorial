{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a3a077f-2666-4046-81f8-cededa37315c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca346c-a23d-4413-ad63-7097291c2281",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2187ccf1-f3a5-432d-84c8-734d0eb5f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d38c5a-02e7-4a64-937b-0156c467f38b",
   "metadata": {},
   "source": [
    "##### Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a535c9-4496-45fb-832a-85ea98ba8bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b4926f-b5d6-4ccc-a3b8-d5a14ec1abf7",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985191fb-0acb-42b1-b45c-d53a122b619e",
   "metadata": {},
   "source": [
    "##### Data loading and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf3a54b-25b9-4d5f-9c45-0571a720c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d1cf2-3d16-4998-bf2c-17c94263cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(60, 65):\n",
    "    sample_image = trainset[idx][0]\n",
    "    display(sample_image.resize((200,200)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bfe721-74ca-4cdd-a80e-fb1dca466c76",
   "metadata": {},
   "source": [
    "##### Dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e5ffa3-dbbd-4579-a7bb-2fe97da1744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a9e2c-1209-46d3-8e7e-e68b37e01f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sample_image.getdata())[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477a1a7e-c6ba-4c06-9236-f8ce3f62c79d",
   "metadata": {},
   "source": [
    "## Data loading preprocessing and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9822f620-d802-4a03-9856-832757577995",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c7aad-bc87-400f-ac03-e88aafd9c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916d357-91ed-4d94-ba5a-a88b69cf9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2c93b8-72f6-4259-9181-967e72d9b5c1",
   "metadata": {},
   "source": [
    "##### Generate dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce74c11-f741-4b4c-8adb-e2f4107ee3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91144e29-20e2-488c-9139-be50f1e8cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d3aa49-da19-4c59-837e-2e94a82b2b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b015102-5747-45d6-99c3-a707302a763c",
   "metadata": {},
   "source": [
    "#### Define classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187a1e47-49fb-48fe-861c-827b3fc1b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f545ab97-58fa-438c-8b07-a51c50385f22",
   "metadata": {},
   "source": [
    "#### Show sample images with their classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a91f58-22b0-43d2-ae22-022832762d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d8e492-468e-403b-95c0-d832fb983ce5",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d5ba0-e008-4883-9b44-4b5b858bd9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617a8a44-0878-48a2-8a9d-6f0f8c302b19",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfb266b-fca4-49e0-a5d4-1df9861c6a78",
   "metadata": {},
   "source": [
    "##### Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1217d64-2dbb-4df9-ab27-37fb3cecaf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2145a249-4012-4493-b2f6-63ca57cbc6ae",
   "metadata": {},
   "source": [
    "##### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6553c-f7ac-4303-9d7d-c8294172e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a5d809-fcd4-4f2b-add0-7e24ef31eda4",
   "metadata": {},
   "source": [
    "##### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13366891-dab9-47dc-a970-e68a97be6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782f06a4-90bb-4f86-af27-8635664cc8ae",
   "metadata": {},
   "source": [
    "##### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d2fe24-0bb9-424c-b84a-c05d92059ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bdcc38-a334-476c-bba8-594d3fc81494",
   "metadata": {},
   "source": [
    "## Test process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d93425b-20c1-40ef-89de-fa326ea4c84c",
   "metadata": {},
   "source": [
    "##### Show sample test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e4248-36ac-41aa-b8e3-5e2835c04397",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33329f33-891e-4274-9eeb-ea3c4fc66666",
   "metadata": {},
   "source": [
    "##### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147408ce-ae9b-4f01-a0eb-8d6663d83da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f0e54-dd2a-4d45-a24d-05c0dd7f4f79",
   "metadata": {},
   "source": [
    "##### Compute predictions on subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a9f93-5521-4b48-80a7-0b190ca0ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3dee10-2379-47ba-b2b9-da0a4c8879c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b13e7-ad6f-451f-a97b-0e17913c1311",
   "metadata": {},
   "source": [
    "##### Compute predictions on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e42851-246e-442e-98cb-289f8f9f45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735cf10f-1733-4de1-96f6-7bf176c8f405",
   "metadata": {},
   "source": [
    "#### Extra: Computing accuracy by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d98b4cb-4b26-45e9-a326-67453e4188c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
